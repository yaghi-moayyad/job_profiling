# Housekeeping
rm(list = ls());
cat('\014');
# Libraries
library(dplyr)
library(lubridate)
library(zoo)
setwd("~/projects/world_bank/job_profiling/r_code")
rm(list = ls())
graphics.off()
# 1| Preparation ----------------------------------------------------------
# 1.1| Libraries ----------------------------------------------------------
myPackages   = c('haven', 'mclust', 'poLCA', 'nlsem', 'depmixS4', 'survival',
'rpart.plot', 'survMisc', 'ggplot2', 'ggparty','partykit',
'treeClust', 'flexmix', 'openxlsx', 'fitdistrplus',
'tidyverse', 'reshape2', 'factoextra', 'ggpubr', 'tidyquant',
'DescTools', 'caret', 'Metrics')
notInstalled = myPackages[!(myPackages %in% rownames(installed.packages()))]
if(length(notInstalled)) {
install.packages(notInstalled)
}
library(haven)        # Reads .dta files.
library(openxlsx)     # Exports the results to excel.
library(partykit)     # Tree-structured regression and classification models.
library(treeClust)    # Produces dissimilarities for tree-based clustering.
library(ggparty)      # Extends ggplot2 functionality to the partykit package. Customizable visualizations for trees.
library(factoextra)   # Dendogram.
library(rpart.plot)   # Plots rpart trees.
library(flexmix)      # Fits discrete mixtures of regression models.
library(fitdistrplus) # Fits of a parametric distribution to non-censored or censored data.
library(poLCA)        # Estimation of latent class and latent class regression models for polytomous outcome variables.
library(nlsem)        # Estimation of Structural Equation Mixture Modeling (SEMM).
library(depmixS4)     # Estimation of dependent mixture models.
library(mclust)       # Model-based clustering, classification, and density estimation (based on finite normal mixture modelling).
library(mclust)       # Model-based clustering, classification, and density estimation (based on finite normal mixture modelling).
library(survival)     # Survival analysis.
library(survMisc)     # Analysis of right censored survival data. Extends the methods available in 'survival'.
library(tidyverse)    # Data manipulation and graph generation.
library(reshape2)     # Data manipulation for graphs in ggplot and export data.
library(extrafont)    # Font according to Word.
library(tidyquant)    # For statistical moments.
library(DescTools)    # To calculate entropy.
library(ggpubr)       # Nice trees.
library(caret)        # Tuning.
library(Metrics)      # RMSE calculation.
library(here)         # Find the folder path
loadfonts(device = 'win') # Load fonts from windows.
loadfonts(device = 'mac') # Load fonts from windows.
options(scipen = 999) # Disable scientific notation.
# 1.2| Working directory --------------------------------------------------
userLocation       = enc2native(here())
#It is assumed that the input and code files exist.
#Existence of output files is checked
if(!file.exists("Output")){
dir.create("Output")
}
if(!file.exists("Output/Evaluation")){
dir.create("Output/Evaluation")
}
if(!file.exists("Output/Simulation")){
dir.create("Output/Simulation")
}
codeLocation       = paste0(userLocation, '/Code/')
inputLocation      = paste0(userLocation, '/Input/')
outputLocation     = paste0(userLocation, '/Output/')
evaluationLocation = paste0(outputLocation, 'Evaluation/')
simulationLocation = paste0(outputLocation, 'Simulation/')
setwd(userLocation)
# Dendrogram's creation ---------------------------------------------------
is.descendant <- function (all.leaves, node) {
if (length (all.leaves) == 0) return (logical (0))
all.leaves <- as.numeric (all.leaves); node <- as.numeric (node)
if (missing (node)) return (NA)
result <- rep (FALSE, length (all.leaves))
for (i in 1:length (all.leaves)) {
result=node<all.leaves
}
return (result)
}
##Large functions
source(paste0(codeLocation, 'Part I Cleaning Training.R'), encoding = 'UTF-8')
source(paste0(codeLocation, 'Part II Training.R'), encoding = 'UTF-8')
source(paste0(codeLocation, 'Part III Cleaning Evaluation.R'), encoding = 'UTF-8')
source(paste0(codeLocation, 'Part IV Evaluation.R'), encoding = 'UTF-8')
source(paste0(codeLocation, 'Part V Simulation.R'), encoding = 'UTF-8')
rm(list = ls())
graphics.off()
# 1| Preparation ----------------------------------------------------------
# 1.1| Libraries ----------------------------------------------------------
myPackages   = c('haven', 'mclust', 'poLCA', 'nlsem', 'depmixS4', 'survival',
'rpart.plot', 'survMisc', 'ggplot2', 'ggparty','partykit',
'treeClust', 'flexmix', 'openxlsx', 'fitdistrplus',
'tidyverse', 'reshape2', 'factoextra', 'ggpubr', 'tidyquant',
'DescTools', 'caret', 'Metrics')
notInstalled = myPackages[!(myPackages %in% rownames(installed.packages()))]
if(length(notInstalled)) {
install.packages(notInstalled)
}
library(haven)        # Reads .dta files.
library(openxlsx)     # Exports the results to excel.
library(partykit)     # Tree-structured regression and classification models.
library(treeClust)    # Produces dissimilarities for tree-based clustering.
library(ggparty)      # Extends ggplot2 functionality to the partykit package. Customizable visualizations for trees.
library(factoextra)   # Dendogram.
library(rpart.plot)   # Plots rpart trees.
library(flexmix)      # Fits discrete mixtures of regression models.
library(fitdistrplus) # Fits of a parametric distribution to non-censored or censored data.
library(poLCA)        # Estimation of latent class and latent class regression models for polytomous outcome variables.
library(nlsem)        # Estimation of Structural Equation Mixture Modeling (SEMM).
library(depmixS4)     # Estimation of dependent mixture models.
library(mclust)       # Model-based clustering, classification, and density estimation (based on finite normal mixture modelling).
library(survival)     # Survival analysis.
library(survMisc)     # Analysis of right censored survival data. Extends the methods available in 'survival'.
library(tidyverse)    # Data manipulation and graph generation.
library(reshape2)     # Data manipulation for graphs in ggplot and export data.
library(extrafont)    # Font according to Word.
library(tidyquant)    # For statistical moments.
library(DescTools)    # To calculate entropy.
library(ggpubr)       # Nice trees.
library(caret)        # Tuning.
library(Metrics)      # RMSE calculation.
library(here)         # Find the folder path
loadfonts(device = 'win') # Load fonts from windows.
options(scipen = 999) # Disable scientific notation.
# 1.2| Working directory --------------------------------------------------
userLocation       = enc2native(here())
#It is assumed that the input and code files exist.
#Existence of output files is checked
if(!file.exists("Output")){
dir.create("Output")
}
if(!file.exists("Output/Evaluation")){
dir.create("Output/Evaluation")
}
if(!file.exists("Output/Simulation")){
dir.create("Output/Simulation")
}
codeLocation       = paste0(userLocation, '/Code/')
codeLocation       = paste0(userLocation, 'Code/')
inputLocation      = paste0(userLocation, '/Input/')
outputLocation     = paste0(userLocation, '/Output/')
evaluationLocation = paste0(outputLocation, 'Evaluation/')
simulationLocation = paste0(outputLocation, 'Simulation/')
setwd(userLocation)
# Dendrogram's creation ---------------------------------------------------
is.descendant <- function (all.leaves, node) {
if (length (all.leaves) == 0) return (logical (0))
all.leaves <- as.numeric (all.leaves); node <- as.numeric (node)
if (missing (node)) return (NA)
result <- rep (FALSE, length (all.leaves))
for (i in 1:length (all.leaves)) {
result=node<all.leaves
}
return (result)
}
##Large functions
source(paste0(codeLocation, 'Part I Cleaning Training.R'), encoding = 'UTF-8')
##Large functions
source(paste0(codeLocation, 'Part I Cleaning Training.R'), encoding = 'UTF-8')
source(paste0(codeLocation, 'Part II Training.R'), encoding = 'UTF-8')
codeLocation       = paste0(userLocation, '/Code/')
##Large functions
source(paste0(codeLocation, 'Part I Cleaning Training.R'), encoding = 'UTF-8')
source(paste0(codeLocation, 'Part II Training.R'), encoding = 'UTF-8')
source(paste0(codeLocation, 'Part III Cleaning Evaluation.R'), encoding = 'UTF-8')
source(paste0(codeLocation, 'Part IV Evaluation.R'), encoding = 'UTF-8')
source(paste0(codeLocation, 'Part V Simulation.R'), encoding = 'UTF-8')
# 2| Unemployment profiling -----------------------------------------------
# 2.1| Three clusters -----------------------------------------------------
startTime  = Sys.time()
clusterNum = 3
wb = openxlsx::createWorkbook(creator = 'WB SP')
cleanTraining    = cleaningTrainingFunction(file = 'Unemployment Data.dta')
cleanTraining    = cleaningTrainingFunction(file = 'Unemployment Data.dta')
#Male case
i="Male"
newTemp = trainingModel(data = cleanTraining, gend = i, clusterNum = 3)
newData = cleaningEvaluationFunction(file = 'NAF Clean Set.dta', gend = i, clusterNum = 3, tb = tb)
dataM     = evaluationModel(data = newData, gend = i, clusterNum = 3, tb = tb)
wb     = simulationChanges(data = newData, gend = i, clusterNum = 3, wb, tb = tb)
newTemp = trainingModel(data = cleanTraining, gend = i, clusterNum = 3)
tb      = list(tr_FirstJob           = newTemp$tr_FirstJob,
tr_Experience         = newTemp$tr_Experience,
tr_Age                = newTemp$tr_Age,
tr_Governorate        = newTemp$tr_Governorate,
tr_Disability         = newTemp$tr_Disability,
tr_EducationLevel     = newTemp$tr_EducationLevel,
tr_Industry           = newTemp$tr_Industry,
tr_UnemploymentSpell  = newTemp$tr_UnemploymentSpell,
sCat                  = newTemp$sCat,
finalDataF            = newTemp$finalDataF)
#Female case
i="Female"
tb      = list(tr_FirstJob           = newTemp$tr_FirstJob,
tr_Experience         = newTemp$tr_Experience,
tr_Age                = newTemp$tr_Age,
tr_Governorate        = newTemp$tr_Governorate,
tr_Disability         = newTemp$tr_Disability,
tr_EducationLevel     = newTemp$tr_EducationLevel,
tr_Industry           = newTemp$tr_Industry,
tr_UnemploymentSpell  = newTemp$tr_UnemploymentSpell,
sCat                  = newTemp$sCat,
finalDataF            = newTemp$finalDataF)
dataF     = evaluationModel(data = newData, gend = i, clusterNum = 3, tb = tb)
newData = cleaningEvaluationFunction(file = 'NAF Clean Set.dta', gend = i, clusterNum = 3, tb = tb)
dataF     = evaluationModel(data = newData, gend = i, clusterNum = 3, tb = tb)
dataT=rbind(dataM,dataF)
tb      = list(tr_FirstJob           = newTemp$tr_FirstJob,
tr_Experience         = newTemp$tr_Experience,
tr_Age                = newTemp$tr_Age,
tr_Governorate        = newTemp$tr_Governorate,
tr_Disability         = newTemp$tr_Disability,
tr_EducationLevel     = newTemp$tr_EducationLevel,
tr_Industry           = newTemp$tr_Industry,
tr_UnemploymentSpell  = newTemp$tr_UnemploymentSpell,
sCat                  = newTemp$sCat,
finalDataF            = newTemp$finalDataF)
newData = cleaningEvaluationFunction(file = 'NAF Clean Set.dta', gend = i, clusterNum = 3, tb = tb)
dataM     = evaluationModel(data = newData, gend = i, clusterNum = 3, tb = tb)
wb     = simulationChanges(data = newData, gend = i, clusterNum = 3, wb, tb = tb)
#Female case
i="Female"
newTemp = trainingModel(data = cleanTraining, gend = i, clusterNum = 3)
newData = cleaningEvaluationFunction(file = 'NAF Clean Set.dta', gend = i, clusterNum = 3, tb = tb)
dataF     = evaluationModel(data = newData, gend = i, clusterNum = 3, tb = tb)
dataT=rbind(dataM,dataF)
write.csv(dataT,paste0(evaluationLocation,"CategorizedData.csv"), row.names = FALSE)
wb     = simulationChanges(data = newData, gend = i, clusterNum = 3, wb, tb = tb)
endTime = Sys.time()
endTime - startTime
tb      = list(tr_FirstJob           = newTemp$tr_FirstJob,
tr_Experience         = newTemp$tr_Experience,
tr_Age                = newTemp$tr_Age,
tr_Governorate        = newTemp$tr_Governorate,
tr_Disability         = newTemp$tr_Disability,
tr_EducationLevel     = newTemp$tr_EducationLevel,
tr_Industry           = newTemp$tr_Industry,
tr_UnemploymentSpell  = newTemp$tr_UnemploymentSpell,
sCat                  = newTemp$sCat,
finalDataF            = newTemp$finalDataF)
saveWorkbook(wb,
file = paste0(simulationLocation, 'Simulation (', clusterNum, ')', '.xlsx'),
overwrite = TRUE)
